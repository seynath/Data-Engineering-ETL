# Quick Reference Card

## ğŸš€ Start the Pipeline
```bash
./pipeline-cli.sh start
```

## ğŸ›‘ Stop the Pipeline
```bash
./pipeline-cli.sh stop
```

## ğŸ“Š Check Status
```bash
./pipeline-cli.sh status
```

## ğŸ”„ Trigger ETL Run
```bash
./pipeline-cli.sh trigger-dag
```

## ğŸ“ View Logs
```bash
./pipeline-cli.sh logs
./pipeline-cli.sh logs airflow-scheduler
```

## ğŸ”§ Troubleshoot
```bash
./pipeline-cli.sh troubleshoot
```

## ğŸŒ Access URLs

| Service | URL | Credentials |
|---------|-----|-------------|
| Airflow | http://localhost:8080 | airflow / airflow |
| Superset | http://localhost:8088 | admin / admin |

## ğŸ’¾ Database Access

```bash
# Warehouse DB
./pipeline-cli.sh db-warehouse

# Airflow DB
./pipeline-cli.sh db-airflow
```

## ğŸ§¹ Clean Restart
```bash
./pipeline-cli.sh clean  # Removes all data
./pipeline-cli.sh start
```

## ğŸ“ Key Directories

- `dataset/` - Source CSV files
- `data/bronze/` - Raw data
- `data/silver/` - Transformed data
- `airflow/logs/` - Pipeline logs
- `config/` - Configuration files

## ğŸ†˜ Emergency Commands

```bash
# Force stop everything
docker-compose down -v

# Check what's running
docker ps

# View specific container logs
docker logs healthcare-etl-airflow-scheduler

# Restart specific service
docker-compose restart airflow-scheduler
```

## âœ… Health Check
All services should show "(healthy)":
```bash
docker ps --format "table {{.Names}}\t{{.Status}}"
```

## ğŸ“š Full Documentation

- `GETTING_STARTED.md` - Start here
- `RUN_PIPELINE.md` - Detailed instructions
- `FIXED_ISSUES.md` - What was fixed
- `README.md` - Project overview

## ğŸ’¡ Pro Tips

- Pipeline runs daily at 2 AM UTC automatically
- Trigger manually anytime from Airflow UI
- Data persists in Docker volumes
- Use `./pipeline-cli.sh help` for all commands
