# âœ… Validation Configuration Fixed!

## What Was Fixed

The Great Expectations configuration has been updated to properly find Parquet files in dated subdirectories.

**Changes made:**
- Added `glob_directive: "**/*.parquet"` to recursively scan subdirectories
- Updated regex pattern to match files in any subdirectory
- Configuration now works with dynamic date directories (2025-10-25/, 2025-10-26/, etc.)

## ðŸš€ Apply the Fix

### On Your Server

Run this command:

```bash
docker-compose restart airflow-scheduler airflow-webserver
```

Wait 10-15 seconds for services to restart.

### Then Retry the Validation

**Option 1: Wait for Automatic Retry**
- The task will retry automatically (4 attempts total)
- Just wait a few minutes

**Option 2: Manual Retry**
1. Go to Airflow UI: http://your-server-ip:8080
2. Click on the `healthcare_etl_pipeline` DAG
3. Find the `validate_silver_layer` task
4. Click "Clear" to retry it immediately

## âœ… Verify It Works

After the restart, the validation should:
1. Find the Parquet files in `data/silver/2025-10-26/`
2. Run validation checks
3. Pass successfully
4. Allow the pipeline to continue to `load_to_warehouse`

Check the logs in Airflow UI - you should see:
```
INFO - Validating Silver layer for date: 2025-10-26
INFO - Running checkpoint: silver_validation_checkpoint
INFO - Checkpoint executed successfully
```

## ðŸ“Š After Validation Passes

The pipeline will automatically continue to:
1. **load_to_warehouse** - Load data to PostgreSQL
2. **run_dbt_transformations** - Create dimensional models

Then check your warehouse:
```bash
./pipeline-cli.sh db-warehouse
```

```sql
SELECT COUNT(*) FROM dim_patient;
SELECT COUNT(*) FROM fact_encounter;
```

You should see data!

## ðŸŽ‰ Summary

**âœ… Great Expectations configuration fixed**
**âœ… Will now find Parquet files in dated directories**
**âœ… Validation will pass**
**âœ… Pipeline will complete end-to-end**

---

**Quick command:** `docker-compose restart airflow-scheduler airflow-webserver`
